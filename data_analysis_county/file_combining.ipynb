{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326168e9-9ef3-433c-a4fc-df5b1331a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from aquacrop.utils import prepare_weather, get_filepath\n",
    "from aquacrop import AquaCropModel, Soil, Crop, InitialWaterContent, IrrigationManagement\n",
    "#from aquacrop.entities import IrrigationManagement\n",
    "from os import chdir, getcwd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "import pickle \n",
    "#from dfply import *\n",
    "\n",
    "import os \n",
    "from os import chdir, getcwd\n",
    "import datetime\n",
    "import shapefile as shp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import geometry\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a987752f-00e3-4a97-9fc9-055a97be8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jupyter-wndlovu/') # change working directory\n",
    "\n",
    "wd=getcwd()\n",
    "#wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c8fe43-c244-4315-a1da-d335acb7c760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add county files\n",
    "# \n",
    "def fileInput(filepath):\n",
    "    \"\"\"This function is used to read input data (.csv files) stored in folders\"\"\"\n",
    "    \n",
    "    path =  filepath# landouse folder path\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))] # read files from folder\n",
    "    dfs_list = []  # List to store the dataframes\n",
    "\n",
    "    for file in files: # read files and save them a list of dataframes\n",
    "        file_path = os.path.join(path, file)\n",
    "        df = pd.read_csv(file_path) \n",
    "        dfs_list.append(df)\n",
    "        \n",
    "    return(dfs_list)\n",
    "\n",
    "\n",
    "def fileList(dataframe):\n",
    "    \"\"\"This function is used to group the gridmet, soils and canopy cover dataframes by the crop, irrigation management and county\"\"\"\n",
    "    \n",
    "    group_dataframe = dataframe.groupby('crop_mn_codeyear')\n",
    "\n",
    "# list to store the dfs\n",
    "    county_list = []\n",
    "\n",
    "# create separate dfs\n",
    "    for i, j in group_dataframe:\n",
    "        county_list.append(j.copy())\n",
    "        \n",
    "    return(county_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccf09c-642e-4dd0-920d-7aa1404f62a9",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42afa65-fb21-4ab0-9ddc-d3e875d46591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gridmet_list = fileInput(wd + '/eggs/gmd4_gridMET')\n",
    "lai_list = fileInput(wd + '/eggs/leaf_area_index') \n",
    "soils_list = fileInput(wd + '/eggs/gmd4_soils_county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d41d86-7cb6-4d1e-a44e-869e4935e5ed",
   "metadata": {},
   "source": [
    "# GridMET wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf7d2f3-ea09-4ce6-b1a4-37c6e1f993d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean the datasets by the \n",
    "gridmet_df = pd.concat(gridmet_list, ignore_index = True)\n",
    "                         \n",
    "                    \n",
    "gridmet_df = gridmet_df.assign(tmmn = gridmet_df.tmmn-273.15, # convert to celcius\n",
    "                    tmmx = gridmet_df.tmmx-273.15,\n",
    "                    date_ymd = pd.to_datetime(gridmet_df['date_ymd'], format='%Y%m%d'))\n",
    "\n",
    "gridmet_df['Year'] = gridmet_df['date_ymd'].dt.year\n",
    "\n",
    "# rename variables\n",
    "gridmet_df  = gridmet_df.rename(columns = {\n",
    "                                'tmmn':'MinTemp',\n",
    "                                'tmmx':'Maxtemp',\n",
    "                                'pr':'Precipitation',\n",
    "                                'eto':'ReferenceET',\n",
    "                                'date_ymd':'Date'\n",
    "                                })\n",
    "\n",
    "gridmet_df = gridmet_df[['crop_mn_codeyear',\n",
    "                         'MinTemp', \n",
    "                         'Maxtemp',\n",
    "                         'Precipitation', \n",
    "                         'ReferenceET',\n",
    "                         'Date',\n",
    "                         'Year'\n",
    "                        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3b5f93-9567-4b96-99ac-f8d09e0cb17f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridmet_county = fileList(gridmet_df)\n",
    "len(gridmet_county)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec73dd8-dceb-483b-9e73-f12f8528f129",
   "metadata": {},
   "source": [
    "# Leaf Area Index Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355c43fe-029b-4b9d-9d8b-fba0731a8c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lai_df = pd.concat(lai_list, ignore_index = True)\n",
    "\n",
    "lai_df = lai_df.assign(cc = (100.5*(1-np.exp(-0.6*lai_df['Lai']))**1.2),\n",
    "                      date = pd.to_datetime(lai_df['date_ymd'], format='%Y%m%d')) # calc canopy cover Hsiao et al. (2009)\n",
    "\n",
    "lai_df['Year'] = lai_df['date'].dt.year\n",
    "\n",
    "lai_df = lai_df[['crop_mn_codeyear', 'Year', 'date', 'Lai', 'cc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4b7274-afbe-4a13-a7c4-a366c274f4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lai_county = fileList(lai_df) \n",
    "len(lai_county)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7bc61d-ed92-4ded-999a-0d3e77a77dc9",
   "metadata": {},
   "source": [
    "# Soils wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09b400f-bd01-4f06-8a9a-106e4027fd9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soils_df = pd.concat(soils_list)\n",
    "\n",
    "soils_df = soils_df[['crop_mn_codeyear', 'Year', 'system:index', 'mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53a59f8-68a9-4b05-8496-d1ea0be4e377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soils_df['variable'] = soils_df['system:index'].str.replace(r'^.*?(?=[a-z])', '', regex=True) # remove all numbers before the firct chr\n",
    "soils_df['soil_var'] = soils_df['variable'].str[:-21] # drop the last 21 characters\n",
    "soils_df['var'] = soils_df['soil_var'].str.rsplit('_', n=2).str[0] # get the soil param\n",
    "soils_df['depth'] =soils_df['soil_var'].str.extract(r'(\\d+_\\d+)') # soil depth\n",
    "soils_df = soils_df[['crop_mn_codeyear', 'Year', 'depth', 'var', 'mean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268866a-292f-49dc-93bb-d6a8537897f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pivot table to match aquacrop input format\n",
    "soils_df_pivot = soils_df.pivot_table(index=['crop_mn_codeyear', 'Year', 'depth'],\n",
    "                                 columns=\"var\", values=\"mean\")\n",
    "\n",
    "soils_df_pivot = soils_df_pivot.assign(om = (10**(soils_df_pivot['om'])), # unit conversion\n",
    "                     ksat = (10**(soils_df_pivot['ksat'])))                                         \n",
    "\n",
    "soils_df_pivot = soils_df_pivot.reset_index()\n",
    "#soils_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d156b29-412a-412d-b161-9234b7f06ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soils_county = fileList(soils_df_pivot) \n",
    "len(soils_county)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c5bf1-a124-4241-badf-54d7dbc4adeb",
   "metadata": {},
   "source": [
    "# Create dictionary with dataframes for each county, mngt and crop combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56166f-4721-447f-8b9c-b6690e61fed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_comb = gridmet_df['crop_mn_codeyear'].unique() # get all unique ids\n",
    "#county_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375119be-39b6-4bc0-9129-1db8abe390e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dict = {}\n",
    "comb_len = len(county_comb)\n",
    "\n",
    "# loop through lists to form dict\n",
    "for i in range(comb_len):\n",
    "    key = str(gridmet_county[i]['crop_mn_codeyear'].unique())\n",
    "    #print(key)\n",
    "    value = (gridmet_county[i], lai_county[i], soils_county[i])\n",
    "    input_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d08ae-9d97-4cb1-bd95-8438564c068c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(input_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6681c3aa-4560-4c78-8b53-13bcae8ec39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save dict as pickle\n",
    "with open(wd + '/eggs/data/input_dict.pickle', 'wb') as input_data: # county crop managemnt\n",
    "    pickle.dump(input_dict, input_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa59d9b-fd0a-455e-858b-43e03726e885",
   "metadata": {},
   "source": [
    "# Next Step - Calibration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eggs2",
   "language": "python",
   "name": "eggs2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
